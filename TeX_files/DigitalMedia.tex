\chapter{Digital Media}

\section{Text}

We've already looked at one method of sending digital text: Morse code. A piece of text is broken up in to a sequence of individual blocks, and somehow the content of that block is specified by a code. A page is broken into a sequence of lines. And each line is broken in to a sequence of characters.\\

\begin{center}\imagegraphic[0.75]{text.png}\end{center}

For a digital text, the available characters are determined first. Basically, a number, or code, is assigned for each separate character we wish to be able to print. Capital letters are separate characters than lower case. A space is a character. More characters are needed for punctuation and other symbols like \$, \&, and any other symbol we wish to be able to represent.\\

We don't want all the text to be on the same line, and so there needs to be a way to tell where the text appears in the vertical direction. Just as there is a character to represent a space, which basically means moving over a certain amount without printing anything, there is a character to represent the action of going to a new line of text without printing anything. This is called the new-line character. Even though we can't 'see' the newline character on a page of text, just like the space character, we can its result. A new-line is usually what happens when you hit 'enter' on your keyboard when typing.\\

Instead of sending dots and dashes, the codes are binary numbers, since our hardware is built to be able to store and send any sequence of bits. Now what numbers, specifically, represent each character? For example, what might be the number for the letter 'A'? Well, it really depends. In some sense the numbers chosen are arbitrary. However, there are certain standards that have been established.\\

If you wish to represent a single character by 8 bits (an 8 bit number), then one of the first standards was the ASCII standard. In ASCII, the letter 'A' is number 65 (in decimal). The letter 'a' is 97. A space is 32, and a new line is 10. Since there are 8 bits to work with, there are 256 possible characters.\\

The ASCII standard is somewhat language specific. Many languages require additional characters. The Unicode standard is a way to add more possible characters needed for other languages and symbols to be written, and itself varies in how many bits are required to represent individual characters. UTF-8 is a variable length 8-bit version which is replacing ASCII. The first 128 characters of UTF-8 are exactly the same as ASCII. When the above message "Have a good day!" is encoded in UTF-8, the result is the following hexadecimal numeric values of the characters.\\

\begin{center}\imagegraphic[0.75]{text_code.png}\end{center}

The message is composed of a total of 16 characters, each requiring 8 bits, or 1 byte, to store. To send this message is then 16 bytes of information. Converted to a string of bits, the above message would look like the following, since each character has to be 8 bits:\\

\begin{verbatim}
01000100011000010111011001100101001000000110000100100000
01100111011011110110111101100100001000000110010001100001 
0111100100100001
\end{verbatim}

The numeric value of a Unicode character must be found in a lookup table. As a shorthand, a format U+\#\#\#\# (where \# are hexadecimal digits) is used to say "this is a Unicode character with a value of \#\#\#\#". So, the letter 'H' is character U+0044. A space is U+0020, and so on. Remember, this is hexadecimal, not decimal: \(20_{hex} = 32_{dec}\).\\

Notice there are 4 reserved digits (2 bytes). Just doing the math, and knowing these are hexadecimal digits, that gives \(16^4 = 65,536\) possibilities here. However, this is just one sub-set of the total Unicode characters. There are currently a total 17 sets, which specifies a total of \(17 \times 65,536 = 1,114,112\) different characters.\\

\section{Text Compression}

Text is an excellent subject for compression, because it is very redundant. The average information content per character of text is usually only about 3 bits (sometimes even lower), versus the 8 bits we might store it as. The reason it doesn't contain quite as much information as we think is because of patterns. A pattern means each character is less surprising, and we might be able to guess what it is. For example, if I just removed some characters from a word by replacing them with asterisks, could you still guess what the word is? What w***s d* y** t***k I *m typ*** i* t*** se****c*?\\

Humans are very good at seeing patterns by instinct, but it's hard to spell out exactly how we do it. What we need is a method, or algorithm, to find a pattern and use it to remove redundant information, but still be able to replace it later to reconstruct the original.\\

One method is called the Lempel-Ziv algorithm. This algorithm looks for a pattern where a specific sequence of characters appears in more than one place in a piece of text. Let's look at an example that contains a lot of redundancy:\\

\begin{verbatim}
How much wood would a woodchuck chuck if a woodchuck could chuck
 wood?
\end{verbatim}

I'm going to scan through the text, and look at pairs of characters. For each pair, I'm going to scan backwards to see if that pair occurred before. If it did, I'm going to replace the pair with a number (in brackets) that says how many characters back it occurred. The idea is if I can replace 2 characters, which would be 16 bits total, with a single number, which I would store as 8 bits, then every replacement would reduce the total by 8 bits.\\

\begin{verbatim}
How much wood[5]oul[6]a[8][13]d[20][23]k [6][6][6]if[21][21][21]
[21][21][21][21][39][39][6][12][12][22][22]d?
\end{verbatim}

The original sentence had 70 characters, or a total of 560 bits. After the replacements it has 24 letters and 23 numbers, for a total of 376 bits. That gives a compression of about 67\%. But it's only useful if it can be reversed.\\

Start scanning from the beginning of the result. When you get to a number in brackets, go backwards that many characters. Get the two characters that start there, and replace the number in brackets with those two characters. For example, the first number is [5]. So I go back 5 characters. The two characters there are " w" (a space, then 'w'), so I replace the [5] with " w", giving the following:

\begin{verbatim}
How much wood woul[6]a[8][13]d[20][23]k [6][6][6]if[21][21][21]
[21][21][21][21][39][39][6][12][12][22][22]d?
\end{verbatim}

The next number is [6]. 6 characters back from that is "d " ('d', then a space).

\begin{verbatim}
How much wood would a[8][13]d[20][23]k [6][6][6]if[21][21][21]
[21][21][21][21][39][39][6][12][12][22][22]d?
\end{verbatim}

Try uncompressing the following message on your own, using the same rules. How many characters are in the original message, and what is the compression factor?

\begin{verbatim}
Can you [8][8]a[6][6][6]s[3][9][9]ner[7][7][4][4][17][6][6]?
\end{verbatim}

The algorithm can be made better by looking at more than 2 characters at a time. Imagine if we can replace entire words with a single number. The compression of text can typically be quite good because of how redundant it really is. However, how much it \textit{can} be compressed is highly dependent on the text itself. How good an algorithm is also usually depends on how much effort is expended to find more obscure patterns. Thus, better compression tends to take longer to perform.

\section{Raster Graphics}

\epigraph{Life isn't always \#000000 and \#FFFFFF. It's a million areas of \#888888.}{\textit{unknown}}

The first step to digitize something is to decide how to break it into a discrete number of elements in a systematic way, where each element can take on one of multiple possible values. Then to assign a code to each possible value an element can have. The codes are what are stored or transmitted. To re-construct the original thing requires knowing the meaning of the codes, and effectively running the deconstruction process in reverse. There are two predominant general methods of storing a digital image: raster, and vector.\\

A raster image is probably the most familiar to you. That is the kind of image displayed on a TV or computer monitor. The idea is to divide a 2-dimensional area into a set of rows and columns which defines a grid of small areas, called pixels. If you look close enough at the screen you can probably make out the individual pixels, each with its own color. The more pixels used, the smoother the image can appear. At some point our eyes blend the individual pixels and colors together into a single image.\\

The following are example raster images of the letter 'J', where each pixel is either black or white. Remember that this is different than sending digital text letter 'J', which only required 1 byte of information. A raster image has to specify the value of every pixel against all the values it \textit{could} be. Thus, a raster image can describe not just this shape, or font, of J, but any other shape that can fit in the same area. The three versions use more pixels (more rows and columns), increasing resolution and making a smoother looking image.\\

\begin{center}\imagegraphic[0.25]{J1.png}\imagegraphic[0.25]{J2.png}\imagegraphic[0.32]{J3.png}\end{center}

First lets look at how the pixel values might be stored. So that I can write out all of the values, I'm going to stick with a 5x5 grid, which would be 25 pixels. And to start out, I will leave all of the squares filled with white. This grid lines are just for guidance to show where the pixels are, and aren't part of the actual picture.\\


\begin{center}\imagegraphic[0.25]{5x5.png}\end{center}

I'm going to write the bit values on a single line, but group them by rows. I'm using a single bit per pixel, and the bit 1 to mean white.\\

\begin{verbatim}
11111 11111 11111 11111 11111
\end{verbatim}

Now I've filled in one of the pixels with black. This will change the value of a single bit. Which bit? Let me write out all the bits again with the change. It's in the 4th row, 2nd column, and so I go to the 4th group of bits, and go to the 2nd bit in that group. I change it from a 1 to a 0, meaning that it's black instead of white.\\

\begin{center}\imagegraphic[0.25]{5x5_1.png}\end{center}

\begin{verbatim}
11111 11111 11111 10111 11111
\end{verbatim}

Now I'm going to try to draw a face. I don't have very many pixels to work with, so you'll have to use your imagination. I'll also give the pixel's bit values.

\begin{center}\imagegraphic[0.25]{5x5_face.png}\end{center}

\begin{verbatim}
11111 10101 11111 10001 11111
\end{verbatim}

So, just to recount what happened, the first 5 bits map to the first row of the image. All first 5 bits are 1s, so all the first row is white. The next group of bits is 10101, which maps to the second row. The first bit on the second group is 1, so the first pixel on the second row is white. The next bit is 0, so the next pixel is black. Then white, then black, then white again which finished the second row. And so on for the 3rd, 4th, and 5th rows.\\

The process will work in reverse as well. If we're given the bits (along with how wide each row is), we can reconstruct the image. Now take the following bits and figure out what the image is by drawing a 5x5 grid and shading in the pixels that have a 0.

\begin{verbatim}
11111 10101 11111 01110 10001
\end{verbatim}

In these examples I only used 1 bit per pixel, which meant it could only be one of two colors (black, or white in this case). But if I use several bits per pixel, there are many more possibilities for each pixel to have different colors. If I used 3 bits for each pixel, that would give \(2^3 = 8\) possibilities. I might use a color code like the following, where each 3-bit binary number mapped to an increasing shade of gray:

\begin{center}\imagegraphic[0.5]{gray.png}\end{center}

Suppose I came up with the following 5x5 image using the 8 shades. When I write the bits out for the image, each pixel is now 3 bits, which means each row takes up 15 bits (\(3\times5\)), and 75 bits total.

\begin{center}\imagegraphic[0.25]{5x5_gradient.png}\end{center}

I'm adding spaces in the bits just to make the groupings more obvious. Just keep in mind that when they are stored or transmitted, the bits are a continuous stream.

\begin{verbatim}
111 000 000 000 000
111 000 001 010 000   
111 000 000 011 000   
111 110 101 100 000   
000 000 000 000 000
\end{verbatim}

With more bits per pixel, comes more possibilities. Since a computer is built to work with bytes, and a byte is 8 bits, a pixel is usually no less than 8 bits. That means for a black and white image there are 256 shades to work with, which is usually enough for a human to not be able to perceive the jumps between shades.\\

\begin{center}\imagegraphic[0.5]{gray32.png}\end{center}

Of course we have gone beyond black and white. So how are full color images stored? This goes back to the basics in art class. You might remember that given a few primary colors, any other color can be created if you mix them in just the right way. And there are two types of color mixing: additive, and subtractive.\\

Computer graphics uses additive color mixing because of how the displays are constructed. You can see something on the computer monitor, or TV, because it is emitting light. Essentially each pixel is really three different pixels. If you could look closely, you would see a red pixel, and green pixel, and a blue pixel packed right next to each other. If the red pixel is made brighter, it can only add more red light. The brightest light is when all three are turned on, making white light. These are the primary colors for additive mixing, and is called the RGB color scheme (or red, green, blue).\\

\begin{center}\imagegraphic[0.75]{RGB_pixels.png}\end{center}
\begin{center}\imagegraphic[0.25]{RGB_pixels2.png}\imagegraphic[0.25]{Dell_axim_LCD_under_microscope.png}
	
http://commons.wikimedia.org/wiki/File:Dell\_axim\_LCD\_under\_microscope.jpg
\end{center}

Just as with a gray scale, each color is represented by an 8-bit number, and so each color, for each pixel, has 256 possibilities: from black (off), all the way up to fully on for that color.\\

\begin{center}red\\ \imagegraphic[0.5]{red32.png}\end{center}
\begin{center}green\\ \imagegraphic[0.5]{green32.png}\end{center}
\begin{center}blue\\ \imagegraphic[0.5]{blue32.png}\end{center}


There is no gray pixel. Shades of gray are made by adding equal parts of each color. However, since they have to be equal, there are still only 256 possible shades of gray, since there are only 256 shades of each color.\\

If the colors are added in non-equal parts, many other colors appear. There are a total of \(256\times256\times256 = 16,777,216 \) possible different colors. In many web-based applications, the RGB values are specified by the literal bit values. This is where hexadecimal numbers come in handy so that we don't have to write out all the bits. Since each color takes 8 bits, that is the same as 2 hexadecimal digits. There are three colors, and so we only need 6 hexadecimal digits to specify a color. The first 2 digits are for red, the next 2 digits are for green, and then blue.\\

\begin{center}\imagegraphic[0.50]{additive.png}\end{center}

For example, to say red would be \#FF0000, since we want red but not green or blue. Remember that in hex, FF is the same as 11111111 in binary. The \# sign comes from historical reasons to mean "rgb color specified by hexadecimal number".\\

\#00FF00 would be green, and \#0000FF would be blue. To make yellow you combine red and green (but not blue), and so yellow would be \#FFFF00. Since magenta is made by combining blue and red, it would be \#FF00FF. Which color would be \#00FFFF? Well, the first 2 digits are zero so you know there's no red. The rest of the digits are F, which means it has full green and blue. Blue and green make the color cyan.\\

There is often a 4th "color" (or channel) added to the mix, called alpha. What this cryptic name basically represents is how opaque the color is. If something is not completely opaque, then you can see stuff behind it like a pane of colored glass. If it is omitted then it is assumed to be completely opaque. If it is included then it appears as a 4th set of hex numbers, where 00 would mean completely transparent, and FF means completely opaque. For example, \#FF0000FF would be red, the same as \#FF0000. But \#FF000077 would mean red that is half-way transparent (since 7 is about halfway to 15, or F in hex).\\

All four channels together would take up \(8\times 4 = 32 \) bits, and so this is called a 32 bit color. If the alpha is ignored, that's 24 bits per pixel. Most graphics you see are using either 24 bit or 32 bit colors.  So, if you have an image that is 1280 by 720, a total of \(1280\times720\times24 = 22,118,400\) bits, or 2,764,800 bytes, are required to store the entire image.\\



\section{Vector Graphics}

Another method of storing an image is called vector graphics. The idea of vector graphics is not to divide the image area in to pixels, storing the color of each pixel, but to divide it in to the primitive shapes that exist in the image such as lines, curves, circles, and rectangles. A vector graphics 'image' is stored independent of the resolution that it will be viewed.\\

When a vector graphic is displayed on a monitor that is made of pixels, the image is rasterized. It is converted to a raster image made up of pixels. The color of each resulting pixel is determined by what is "under" that pixel, and the color of the thing that is under it.\\

One useful application of vector graphics is in Fonts and type-setting. Instead of storing a raster image of each letter, it's better to simply store the outline of the letter as a series of curves. Then, when the letter is displayed or printed it is rasterized based on the resolution and size that is desired. Letters and words can be made larger or smaller without worrying about 'jaggies' appearing due to the limited resolution of an original image of the letter.\\

The most prominent use of vector graphics you are probably familiar with is computer games. A game is not made of a series of static raster images like a movie. What you see is determined in real-time by what you are doing. The information about position, orientation, and general state about a scene is stored as vector data. Then it is rasterized by either your cpu or the graphics card on your computer to produce the image on your screen. This works for both 2D and 3D graphics.\\



\section{Audio}

\epigraph{Art is how we decorate space; music is how we decorate time.}{unknown}

Audio was first digitized in the development of the telephone network. Before they worked digitally, telephones operated on an analog system. The sound of the voice of a person was translated into a voltage by a microphone, and those voltages were carried directly by wires over large distances to a another telephone. The problem was that over large distances the signals became distorted. This is different than just becoming weaker, since amplifiers could be used to boost the amplitude, or loudness, of the signal.\\

Distortion is where the shape of the wave itself changes, and so the sound coming out of one telephone would be different than what went into the other one, even though it had been amplified to be just as loud. Distortion is caused by several factors, which are not important at this point. What is important is how this problem was solved.\\

Audio signals are digitized in a similar fashion as raster images. A sound wave is divided up in time, rather than area. The pressure, or loudness, of the wave is recorded at intervals of time just like the brightness of an image is recorded. A number, or code, is assigned to that chunk of time to say how loud it was at that moment. This method is called pulse-code modulation (PCM).

If the chunks of time are small enough, and number of possible 'loudness' levels is high enough, then the sound can be reproduced by causing a speaker to make sound with the correct loudness at exactly the right times.\\

\begin{center}\imagegraphic[0.75]{sound_1.png}\end{center}
\begin{center}\imagegraphic[0.75]{sound_2.png}\end{center}

So, how did this revolutionize telephones? Since the sound is now a series of numbers, and numbers can be represented by bits, the original audio is converted into a series of 1s and 0s. Each sample is converted into many pulses of 1s and 0s to represent the number that corresponds to how loud the sound is at that moment, instead of sending the sound directly. Suppose each sample is recorded in 8 bits, then every 8 bits gets converted back into a single pulse.\\

Those 1s and 0s are transmitted over the telephone line as voltages just as the analog audio used to be. However, since the machinery knows exactly what a 1 looks like, and what a 0 looks like, as they come over the line it can reconstruct the stream of bits even if the signal is slightly distorted. It couldn't do that with the normal audio because it doesn't know what the original was supposed to sound like. But since it knows what a 1 'sounds' like, and what a 0 'sounds' like, it can make a really good guess as to what they're supposed to be and make them perfect again. Keep in mind that this waveform is not the original signal, but representing the 1s and 0s of the codes.\\

\begin{center}\imagegraphic[0.75]{regenerative.png}\end{center}

Every so often down the telephone line a piece of equipement would take the signal and regenerate it back into the correct form. These are called regenerative repeaters, and their only function is to keep the digital signal together as it's being transmitted even when there is distortion or noise.\\

Now that the bits are ensured to arrive at the destination with the correct values, the original audio is reconstructed performing the PCM in reverse.

\begin{center}\imagegraphic[0.75]{sound_1.png}\end{center}

The two values that describe the quality of digital audio is bit depth and sample rate. Bit depth is how many bits are used per sample, and determine how many 'loudness' levels are possible to represent per sample (like how many color levels in an image). The more bits, the higher the quality, and is either 16 or 24 bits for high quality audio.\\

The sample rate is exactly what it sounds like; the number of samples per unit of time. This is analogous to the resolution of an image. Basically, how many divisions 1 second of sound gets divided into. The sample rate determines the maximum frequency that can be captured. Basically, the sample rate has to be twice as big as the biggest frequency you want to record. The human hearing range is from 20Hz up to 20,000Hz. To capture any sounds we can hear, then the sample rate needs to be above 40kHz (40,000 samples, or divisions, per second). High quality digital audio sample rate is usually set at 44.1kHz. The extra 4.1kHz are used to enable filtering, to smooth out the sound jaggies, so that the resulting maximum frequency is still 20kHz.\\

However, the telephone system used a sample rate of only around 8kHz, which meant it could only pick up frequncies up to around 4kHz. This is why sounds through the telephone don't sound quite right; the higher frequencies are all cut out.

\section{MIDI}

The audio equivalent of vector graphics is midi data, Musical Instrument Digital Interface. The idea is not to store the literal sound waves, but instead store when certain notes are supposed to be played and a reference to how the sounds should be generated (like a musical instrument).\\

MIDI files are written in a similar way that sheet music is written. Each note has to specify when it should be played, the tone at which it's played, and for how long.


\section{General Compression}

Most images that you encounter are already compressed in some way. Like with text, images tend to be redundant in their information, and so they don't take as many bits to store as it would seem. In a strange inversion of intuition, a purely random image actually contains more information than a recognizable image.

\begin{center}\imagegraphic[0.750]{noise.png}\end{center}

The above image is an example of "noise". Every pixel in the image was set to a random RGB value. The image is \(400 \times 400 = 16,000\) pixels, but there are 16,777,216 possible 24bit colors, and so the probability of a color being repeated even once is very small. There is no repetition or pattern that can be used to compress the image, even in principle, and is so called incompressible.\\

The reason a random image contains more information is because there are many more possible "noise" images than "recognizable" images. And so if we want to store one particular "noise" image, we have to specify what makes it different than all the other "noise" images.\\

The reason we, as humans, don't think a noise image contains any information is because all noise images look the same to us: we can't really tell the difference. I'm sure you would be hard pressed to tell the difference between the following image and the previous one with just a glance, even though every single pixel is different between the two.\\

\begin{center}\imagegraphic[0.75]{noise2.png}\end{center}

Ok, so now you believe me that we need a pattern to be able to compress something. There are many different compression algorithms. Some work the same way as described for text compression, except it just looks at sequences of bytes without interpreting them as letters. Compression can be used on any type of digital media because they are all just made up of a series of bits. Any types of patterns in the bits can be used to compress the data, it is just a matter of figuring out how (the algorithm).\\

However, some image compression algorithms use what is called lossy compression. That is, the original image cannot be reconstructed exactly. This \textit{can} be acceptable because we humans usually can't tell the difference between two images that have only subtle differences. So a compression algorithm can get away with throwing away some information if it 'looks' the same to a human, even if it's not exactly the same image anymore.\\

As an example, the first image below is compressed with a lossless algorithm, the second one with a lossy algorithm. The second image has lost some details, but has a file size 20x smaller than the first image. If you look closely you may notice differences in colors and shapes of some features. But if the two images were not next to each other you might not notice it.

\begin{center}\imagegraphic[0.75]{picture_bw.png}\end{center}
\begin{center}\imagegraphic[0.75]{picture_bw.jpg}\end{center}

\section{Chapter Puzzles}